import threading
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import CompressedImage, JointState
import cv2
import numpy as np
import torch
import gradio as gr
from pathlib import Path
from lerobot.datasets.lerobot_dataset import LeRobotDataset
import shutil
import time
import os

# í—ˆë¸Œ ì ‘ì† ì°¨ë‹¨ (ë¡œì»¬ ìš°ì„ )
os.environ["HF_HUB_OFFLINE"] = "1"

KINECT_TOPIC        = "/kinect/color/compressed"
KINECT_DICT         = "kinect_camera"

RIGHT_WRIST_TOPIC   = "/right/camera/cam_wrist/color/image_rect_raw/compressed"
RIGHT_STATE_TOPIC   = "/right/joint_states"
RIGHT_WRIST_DICT    = "right_wrist_camera"


class GradioLeRobotVideoRecorder(Node):
    def __init__(self):
        super().__init__('gradio_lerobot_video_recorder')
        self.lock = threading.Lock()

        self.dataset = None
        self.repo_id = ""
        self.root_path = None
        self.task_name = "default_task"

        self.is_recording = False
        self.is_saving = False
        self.frame_count = 0
        self.current_frame_for_ui = None
        self.current_frame_secondary_for_ui = None

        self.max_time = 10.0
        self.start_time = 0.0
        self.elapsed_time = 0.0
        self.status_msg = "ëŒ€ê¸° ì¤‘"

        # í•´ìƒë„ ì €ì¥ìš©
        self.res_main = "0x0" # í‚¤ë„¥íŠ¸ í•´ìƒë„
        self.res_sub = "0x0"  # ì˜¤ë¥¸ìª½ ì¹´ë©”ë¼ í•´ìƒë„

        # ìƒíƒœ ë° ì•¡ì…˜ (6 joints + 1 gripper = 7)
        self.latest_data = {
            KINECT_DICT: None,
            RIGHT_WRIST_DICT: None,
            "state": torch.zeros(7),
            "action": torch.zeros(7)
        }

        self.joint_names = [
            'right_joint1', 'right_joint2', 'right_joint3',
            'right_joint4', 'right_joint5', 'right_joint6',
            'right_rh_r1_joint'
        ]

        # 1ë²ˆ ì¹´ë©”ë¼ (Kinect)
        self.subscription = self.create_subscription(
            CompressedImage, KINECT_TOPIC, self._kinect_callback, 10)

        # 2ë²ˆ ì¹´ë©”ë¼ (Right Wrist)
        self.subscription_secondary = self.create_subscription(
            CompressedImage, RIGHT_WRIST_TOPIC, self._right_wrist_callback, 10)

        # ì˜¤ë¥¸ìª½ ë¡œë´‡ ì¡°ì¸íŠ¸ ìƒíƒœ (7 joints)
        self.joint_subscription = self.create_subscription(
            JointState, RIGHT_STATE_TOPIC, self._joint_state_callback, 10)

        self.create_timer(1.0 / 30.0, self._recording_loop)

    def get_ep_count(self):
        return self.dataset.num_episodes if self.dataset is not None else 0

    def init_dataset(self, repo_id, root_dir, task_name): # task_name ì¸ì ì¶”ê°€
        with self.lock:
            try:
                self.repo_id = repo_id
                self.root_path = Path(root_dir).absolute()
                self.task_name = task_name # ì…ë ¥ë°›ì€ í…ŒìŠ¤í¬ ì´ë¦„ ì €ì¥
                dataset_path = self.root_path / self.repo_id
                info_json = dataset_path / "meta" / "info.json"

                print("root path: ", self.root_path)
                print("dataset_path: ", dataset_path)

                if info_json.exists():
                    self.dataset = LeRobotDataset(repo_id=self.repo_id, root=dataset_path)
                    self.status_msg = "ğŸ“‚ ê¸°ì¡´ ë°ì´í„°ì…‹ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤."
                else:
                    # TODO: Features ì„¤ì •
                    self.dataset = LeRobotDataset.create(
                        repo_id=self.repo_id,
                        root=dataset_path,
                        fps=30,
                        robot_type= "omy_f3m",
                        features={
                            "timestamp": {
                                "dtype": "float32",
                                "shape": (1),
                                "names": None,
                                "fps": 30
                            },
                            "frame_index": {
                                "dtype": "int64",
                                "shape": (1),
                                "names": None,
                                "fps": 30
                            },
                            "episode_index": {
                                "dtype": "int64",
                                "shape": (1),
                                "names": None,
                                "fps": 30
                            },
                            "index": {
                                "dtype": "int64",
                                "shape": (1),
                                "names": None,
                                "fps": 30
                            },
                            "task_index": {
                                "dtype": "int64",
                                "shape": (1),
                                "names": None,
                                "fps": 30
                            },

                            "observation.images.cam_top": {
                                "dtype": "video",
                                "shape": (1280, 720, 3),
                                "names": ["width", "height", "channels"],
                                "info": {
                                    "video.height": 720,
                                    "video.width": 1280,
                                    "video.channels": 3,
                                    "video.codec": "libx264",
                                    "video.pix_fmt": "yuv420p"
                                }

                            },
                            "observation.images.right_cam_wrist": {
                                "dtype": "video",
                                "shape": (848, 480, 3),
                                "names": ["width", "height", "channels"],
                                "info": {
                                    "video.height": 480,
                                    "video.width": 848,
                                    "video.channels": 3,
                                    "video.codec": "libx264",
                                    "video.pix_fmt": "yuv420p"
                                }

                            },
                            "observation.state": {
                                "dtype": "float32",
                                "shape": (7,),
                                "names": [
                                    "right_joint1",
                                    "right_joint2",
                                    "right_joint3",
                                    "right_joint4",
                                    "right_joint5",
                                    "right_joint6",
                                    "right_rh_r1_joint"
                                ]
                            },
                            "action": {
                                "dtype": "float32",
                                "shape": (7,),
                                "names": [
                                    "right_joint1",
                                    "right_joint2",
                                    "right_joint3",
                                    "right_joint4",
                                    "right_joint5",
                                    "right_joint6",
                                    "right_rh_r1_joint"
                                ]
                            },
                        },
                        use_videos=True,
                    )
                    self.status_msg = f"ğŸ“‚ ìƒˆë¡œìš´ ë°ì´í„°ì…‹ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤."
                return self.status_msg, self.get_ep_count()

            except Exception as e:
                self.status_msg = f"âŒ ì˜¤ë¥˜: {str(e)}"
                return self.status_msg, 0


    def _joint_state_callback(self, msg):
        """ì¡°ì¸íŠ¸ ë°ì´í„° ìˆ˜ì‹  ì½œë°±"""
        current_joints = []

        for name in self.joint_names:
            if name in msg.name:
                idx = msg.name.index(name)
                current_joints.append(msg.position[idx])

        if len(current_joints) == 7:
            with self.lock:
                joint_tensor = torch.tensor(current_joints, dtype=torch.float32)
                self.latest_data["state"] = joint_tensor
                self.latest_data["action"] = joint_tensor

    def _kinect_callback(self, msg):
        """í‚¤ë„¥íŠ¸ ë°ì´í„° ìˆ˜ì‹  ì½œë°±"""
        np_arr = np.frombuffer(msg.data, np.uint8)
        img_raw = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
        if img_raw is not None:
            self.res_main = f"{img_raw.shape[1]}x{img_raw.shape[0]}"
            with self.lock:
                rgb = cv2.cvtColor(img_raw, cv2.COLOR_BGR2RGB)
                self.latest_data[KINECT_DICT] = rgb
                self.current_frame_for_ui = rgb

    def _right_wrist_callback(self, msg):
        """ì˜¤ë¥¸ìª½ ì†ëª© ì¹´ë©”ë¼ ë°ì´í„° ìˆ˜ì‹  ì½œë°±"""
        np_arr = np.frombuffer(msg.data, np.uint8)
        img_raw = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
        if img_raw is not None:
            self.res_sub = f"{img_raw.shape[1]}x{img_raw.shape[0]}"
            with self.lock:
                rgb = cv2.cvtColor(img_raw, cv2.COLOR_BGR2RGB)
                self.latest_data[RIGHT_WRIST_DICT] = rgb
                self.current_frame_secondary_for_ui = rgb

    def _recording_loop(self):
        """ë°ì´í„° ë…¹í™” ë£¨í”„"""
        if not self.is_recording or self.dataset is None:
            return
        with self.lock:
            if self.latest_data[KINECT_DICT] is None:
                self.status_msg = "âš ï¸ í‚¤ë„¥íŠ¸ ë°ì´í„° ì—†ìŒ"
                return

            if self.latest_data[RIGHT_WRIST_DICT] is None:
                self.status_msg = "âš ï¸ ì˜¤ë¥¸ìª½ ì†ëª© ì¹´ë©”ë¼ ë°ì´í„° ì—†ìŒ"
                return


            self.elapsed_time = time.time() - self.start_time
            if self.elapsed_time >= self.max_time:
                self.is_recording = False
                threading.Thread(target=self._save_episode_internal, daemon=True).start()
                return

            img_tensor = torch.from_numpy(self.latest_data[KINECT_DICT]).permute(1, 0, 2)
            img_secondary_tensor = torch.from_numpy(self.latest_data[RIGHT_WRIST_DICT]).permute(1, 0, 2)

            # TODO: ë°ì´í„° ì¶”ê°€
            self.dataset.add_frame({
                "observation.images.cam_top": img_tensor,
                "observation.images.right_cam_wrist": img_secondary_tensor,
                "observation.state": self.latest_data["state"],
                "action": self.latest_data["action"],
                "task": self.task_name
            })
            self.frame_count += 1

    def _save_episode_internal(self):
        with self.lock:
            if self.frame_count == 0:
                self.status_msg = "âš ï¸ ë°ì´í„° ì—†ìŒ"
                self.is_saving = False
                return

            self.is_saving = True
            self.is_recording = False
            self.status_msg = "ğŸ’¾ ì €ì¥ ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”"

            try:
                self.dataset.save_episode()
                gr.Info(f"âœ… ì—í”¼ì†Œë“œ {self.dataset.num_episodes - 1} ì €ì¥ ì™„ë£Œ!")
                self.status_msg = "âœ… ì €ì¥ ì™„ë£Œ"
            except Exception as e:
                self.status_msg = "âŒ ì €ì¥ ì˜¤ë¥˜"
            finally:
                self.frame_count = 0
                self.elapsed_time = 0.0
                self.is_saving = False

    def start_rec(self):
        """ë…¹í™” ì‹œì‘ ë²„íŠ¼"""
        if self.dataset is None:
            self.status_msg = "âš ï¸ ë°ì´í„°ì…‹ ì´ˆê¸°í™”/ë¶ˆëŸ¬ì˜¤ê¸°ë¥¼ ë¨¼ì € í•´ì£¼ì„¸ìš”"
            return self.status_msg, 0, ""
        if self.is_recording:
            self.status_msg = "âš ï¸ ì´ë¯¸ ë…¹í™” ì¤‘ì…ë‹ˆë‹¤"
            return self.status_msg
        with self.lock:
            self._clear_buffer_internal()
            self.is_recording = True
            self.frame_count = 0
            self.start_time = time.time()
            self.elapsed_time = 0.0
            self.status_msg = "ğŸ”´ ë…¹í™” ì¤‘..."
        return self.status_msg, self.get_ep_count(), ""

    def retry_rec(self):
        """ì¬ì‹œì‘ ë²„íŠ¼"""
        if self.dataset is None: return self.status_msg, 0, ""
        with self.lock:
            self._clear_buffer_internal()
            self.is_recording = True
            self.frame_count = 0
            self.start_time = time.time()
            self.status_msg = "ğŸ”„ ì¬ì‹œë„ ì¤‘"
        return self.status_msg, self.get_ep_count(), ""

    def _clear_buffer_internal(self):
        """ë…¹í™”ì¤‘ì¸ ë°ì´í„° ë²„í¼ ì´ˆê¸°í™”"""
        if self.dataset is not None:
            if hasattr(self.dataset, 'clear_episode_buffer'):
                self.dataset.clear_episode_buffer()
            else:
                self.dataset._frames = []

    def next_episode(self):
        """ì—í”¼ì†Œë“œ ì™„ë£Œ ë²„íŠ¼"""
        if self.dataset is None: return self.status_msg, 0, ""
        if self.is_recording:
            self.is_recording = False
            threading.Thread(target=self._save_episode_internal, daemon=True).start()
        return self.status_msg, self.get_ep_count(), ""

    def finalize_dataset(self):
        """ë°ì´í„°ì…‹ ìˆ˜ì§‘ ì¢…ë£Œ ë²„íŠ¼"""
        if self.dataset is None: return "âš ï¸ ë¯¸ì„¤ì •", 0, ""
        with self.lock:
            self.dataset.finalize()
            self.status_msg = "ğŸ ìˆ˜ì§‘ ì¢…ë£Œ"
            return self.status_msg, self.get_ep_count(), ""

    def update_ui_components(self):
        """UI ì»´í¬ë„ŒíŠ¸ ì—…ë°ì´íŠ¸"""
        progress_val = 0
        bar_label = f"ì¤€ë¹„ ì™„ë£Œ: ìµœëŒ€ {self.max_time:.1f}s"
        if self.is_recording:
            progress_val = min(100, (self.elapsed_time / self.max_time) * 100)
            bar_label = f"âŒ› ë…¹í™” ì¤‘: {self.elapsed_time:.1f}s / {self.max_time:.1f}s"
        elif self.is_saving:
            progress_val, bar_label = 100, "ğŸ’¾ ì €ì¥ ì¤‘..."

        with self.lock:
            joints_deg = [np.rad2deg(val.item()) for val in self.latest_data["state"]]
            joint_str = (f"J1:{joints_deg[0]:>6.1f}Â° | J2:{joints_deg[1]:>6.1f}Â° | J3:{joints_deg[2]:>6.1f}Â°\n"
                         f"J4:{joints_deg[3]:>6.1f}Â° | J5:{joints_deg[4]:>6.1f}Â° | J6:{joints_deg[5]:>6.1f}Â°\n"
                         f"Gripper: {joints_deg[6]:.1f}Â°")

            main_label = f"Kinect camera | {self.res_main}"
            sub_label = f"Right Wrist Camera | {self.res_sub}"

        return (
            gr.update(value=self.current_frame_for_ui, label=main_label),
            gr.update(value=self.current_frame_secondary_for_ui, label=sub_label),
            gr.update(value=progress_val, label=bar_label),
            self.status_msg,
            self.get_ep_count(),
            joint_str
        )

# --- UI í•¨ìˆ˜ ---
def launch_ui(server_name:str, port:int, dt:float):
    if not rclpy.ok(): rclpy.init()
    recorder = GradioLeRobotVideoRecorder()
    threading.Thread(target=lambda: rclpy.spin(recorder), daemon=True).start()

    with gr.Blocks(title="LeRobot Collector v3.4") as demo:
        gr.Markdown("# ğŸ¤– LeRobot v3.4 ë©€í‹°ìº  ìˆ˜ì§‘ê¸° (Task ì„¤ì • ì¶”ê°€)")

        with gr.Accordion("âš™ï¸ ì„¤ì •", open=True):
            with gr.Row():
                repo_id_input = gr.Textbox(label="Repo ID", value="uon/HERE_DATASET_NAME")
                root_path_input = gr.Textbox(label="Root Path", value="outputs")
                task_name_input = gr.Textbox(label="Task Name", value="HERE_TASK_NAME")
            with gr.Row():
                max_time_input = gr.Number(label="ìµœëŒ€ ì‹œê°„(ì´ˆ)", value=10.0)
            init_btn = gr.Button("ğŸ”„ ë°ì´í„°ì…‹ ì´ˆê¸°í™”/ë¶ˆëŸ¬ì˜¤ê¸°")

        with gr.Row():
            with gr.Column(scale=2):
                with gr.Row():
                    image_output = gr.Image(label="Kinect camera")
                    image_secondary_output = gr.Image(label="Right wrist camera")
                joint_info_display = gr.Textbox(label="í˜„ì¬ ë¡œë´‡ ì¡°ì¸íŠ¸ ê°ë„ (Degree)", lines=3, interactive=False)
                progress_bar = gr.Slider(label="ì¤€ë¹„ ì™„ë£Œ", minimum=0, maximum=100, value=0, interactive=False)

            with gr.Column(scale=1):
                ep_count_display = gr.Label(value="0", label="í˜„ì¬ ì—í”¼ì†Œë“œ ìˆ˜")
                status_text = gr.Label(value="ëŒ€ê¸° ì¤‘", label="í˜„ì¬ ìƒíƒœ")
                start_btn = gr.Button("ğŸ”´ ë…¹í™” ì‹œì‘", variant="primary")
                next_btn = gr.Button("ğŸ’¾ ì—í”¼ì†Œë“œ ì™„ë£Œ", variant="secondary")
                finish_btn = gr.Button("ğŸ ë°ì´í„° ìˆ˜ì§‘ ì¢…ë£Œ", variant="stop")

        gr.Timer(dt).tick(
            recorder.update_ui_components,
            outputs=[image_output, image_secondary_output, progress_bar, status_text, ep_count_display, joint_info_display]
        )

        # ì´ˆê¸°í™” ë²„íŠ¼ í´ë¦­ ì‹œ task_name_inputë„ í•¨ê»˜ ì „ë‹¬
        init_btn.click(
            recorder.init_dataset,
            inputs=[repo_id_input, root_path_input, task_name_input],
            outputs=[status_text, ep_count_display]
        )

        start_btn.click(recorder.start_rec, outputs=[status_text, ep_count_display])
        next_btn.click(lambda: (recorder.next_episode()[0], recorder.get_ep_count()), outputs=[status_text, ep_count_display])
        finish_btn.click(recorder.finalize_dataset, outputs=[status_text, ep_count_display])

    demo.launch(server_name=server_name, server_port=port)
    rclpy.shutdown()

if __name__ == "__main__":
    launch_ui(
        server_name="127.0.0.1",
        port=7890,
        dt=1/60
    )