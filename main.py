import threading
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import CompressedImage, JointState
import cv2
import numpy as np
import torch
import gradio as gr
from pathlib import Path
from lerobot.datasets.lerobot_dataset import LeRobotDataset
import shutil
import time
import os

# í—ˆë¸Œ ì ‘ì† ì°¨ë‹¨ (ë¡œì»¬ ìš°ì„ )
os.environ["HF_HUB_OFFLINE"] = "1"

class GradioLeRobotVideoRecorder(Node):
    def __init__(self):
        super().__init__('gradio_lerobot_video_recorder')
        self.lock = threading.Lock()

        self.dataset = None
        self.repo_id = ""
        self.root_path = None

        self.is_recording = False
        self.is_saving = False
        self.frame_count = 0
        self.current_frame_for_ui = None
        self.current_frame_secondary_for_ui = None

        self.max_time = 10.0
        self.start_time = 0.0
        self.elapsed_time = 0.0
        self.status_msg = "ëŒ€ê¸° ì¤‘"

        # í•´ìƒë„ ì €ì¥ìš©
        self.res_main = "0x0" # í‚¤ë„¥íŠ¸ í•´ìƒë„
        self.res_sub = "0x0"  # ì˜¤ë¥¸ìª½ ì¹´ë©”ë¼ í•´ìƒë„

        # ìƒíƒœ ë° ì•¡ì…˜ (6 joints + 1 gripper = 7)
        self.latest_data = {
            "image": None,
            "image_secondary": None,
            "state": torch.zeros(7),
            "action": torch.zeros(7)
        }

        self.joint_names = [
            'right_joint1', 'right_joint2', 'right_joint3',
            'right_joint4', 'right_joint5', 'right_joint6',
            'right_rh_r1_joint'
        ]

        # 1ë²ˆ ì¹´ë©”ë¼ (Kinect)
        self.subscription = self.create_subscription(
            CompressedImage, '/kinect/color/compressed', self._kinect_callback, 10)

        # 2ë²ˆ ì¹´ë©”ë¼ (Right Wrist)
        self.subscription_secondary = self.create_subscription(
            CompressedImage, '/right/camera/cam_wrist/color/image_rect_raw/compressed', self._secondary_callback, 10)

        # ì˜¤ë¥¸ìª½ ë¡œë´‡ ì¡°ì¸íŠ¸ ìƒíƒœ (7 joints)
        self.joint_subscription = self.create_subscription(
            JointState, '/right/joint_states', self._joint_state_callback, 10)

        self.create_timer(1.0 / 30.0, self._recording_loop)

    def get_ep_count(self):
        return self.dataset.num_episodes if self.dataset is not None else 0

    def init_dataset(self, repo_id, root_dir):
        with self.lock:
            try:
                self.repo_id = repo_id
                self.root_path = Path(root_dir).absolute()
                dataset_path = self.root_path / self.repo_id
                info_json = dataset_path / "meta" / "info.json"

                if info_json.exists():
                    self.dataset = LeRobotDataset(repo_id=self.repo_id, root=dataset_path)
                    self.status_msg = "ğŸ“‚ ê¸°ì¡´ ë°ì´í„°ì…‹ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤."
                else:
                    self.dataset = LeRobotDataset.create(
                        repo_id=self.repo_id,
                        root=dataset_path,
                        fps=30,
                        features={
                            "observation.image": {
                                "dtype": "video",
                                "shape": (3, 720, 1280),
                                "names": ["channels", "height", "width"],
                                "info": {"fps": 30, "video_backend": "pyav"}
                            },
                            "observation.image_secondary": {
                                "dtype": "video",
                                "shape": (3, 480, 848),
                                "names": ["channels", "height", "width"],
                                "info": {"fps": 30, "video_backend": "pyav"}
                            },
                            "observation.state": {"dtype": "float32", "shape": (7,)},
                            "action": {"dtype": "float32", "shape": (7,)},
                        },
                        use_videos=True,
                    )
                    self.status_msg = f"ğŸ“‚ ìƒˆë¡œìš´ ë°ì´í„°ì…‹ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤."
                return self.status_msg, self.get_ep_count()

            except Exception as e:
                self.status_msg = "âŒ ê¸°ì¡´ ë°ì´í„°ì…‹ ê²½ë¡œë¥¼ ì œê±°í•˜ì„¸ìš”"
                return self.status_msg, 0


    def _joint_state_callback(self, msg):
        """ì¡°ì¸íŠ¸ ë°ì´í„° ìˆ˜ì‹  ì½œë°±"""
        current_joints = []

        for name in self.joint_names:
            if name in msg.name:
                idx = msg.name.index(name)
                current_joints.append(msg.position[idx])

        if len(current_joints) == 7:
            with self.lock:
                joint_tensor = torch.tensor(current_joints, dtype=torch.float32)
                self.latest_data["state"] = joint_tensor
                self.latest_data["action"] = joint_tensor


    def _kinect_callback(self, msg):
        """í‚¤ë„¥íŠ¸ ë°ì´í„° ìˆ˜ì‹  ì½œë°±"""
        np_arr = np.frombuffer(msg.data, np.uint8)
        img_raw = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
        if img_raw is not None:
            self.res_main = f"{img_raw.shape[1]}x{img_raw.shape[0]}"
            with self.lock:
                rgb = cv2.cvtColor(img_raw, cv2.COLOR_BGR2RGB)
                self.latest_data["image"] = rgb
                self.current_frame_for_ui = rgb

    def _secondary_callback(self, msg):
        """ì˜¤ë¥¸ìª½ ì†ëª© ì¹´ë©”ë¼ ë°ì´í„° ìˆ˜ì‹  ì½œë°±"""
        np_arr = np.frombuffer(msg.data, np.uint8)
        img_raw = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
        if img_raw is not None:
            self.res_sub = f"{img_raw.shape[1]}x{img_raw.shape[0]}"
            with self.lock:
                rgb = cv2.cvtColor(img_raw, cv2.COLOR_BGR2RGB)
                self.latest_data["image_secondary"] = rgb
                self.current_frame_secondary_for_ui = rgb

    def _recording_loop(self):
        """ë°ì´í„° ë…¹í™” ë£¨í”„"""
        if not self.is_recording or self.dataset is None:
            return
        with self.lock:
            if self.latest_data["image"] is None:
                self.status_msg = "âš ï¸ í‚¤ë„¥íŠ¸ ë°ì´í„° ì—†ìŒ"
                return # í‚¤ë„¥íŠ¸ ë°ì´í„° ì—†ìœ¼ë©´ ë„˜ì–´ê°

            if self.latest_data["image_secondary"] is None:
                self.status_msg = "âš ï¸ ì˜¤ë¥¸ìª½ ì†ëª© ì¹´ë©”ë¼ ë°ì´í„° ì—†ìŒ"
                return # ì˜¤ë¥¸ìª½ ì†ëª© ì¹´ë©”ë¼ ë°ì´í„° ì—†ìœ¼ë©´ ë„˜ì–´ê°


            self.elapsed_time = time.time() - self.start_time
            if self.elapsed_time >= self.max_time:
                # ì—í”¼ì†Œë“œì˜ ìµœëŒ€ ë…¹í™” ì‹œê°„ì„ ë„˜ì–´ê°
                self.is_recording = False # ë…¹í™” ì¤‘ì§€
                threading.Thread(target=self._save_episode_internal, daemon=True).start() # ì—í”¼ì†Œë“œ ì €ì¥
                return

            img_tensor = torch.from_numpy(self.latest_data["image"]).permute(2, 0, 1)
            img_secondary_tensor = torch.from_numpy(self.latest_data["image_secondary"]).permute(2, 0, 1)

            # í”„ë ˆì„ ì¶”ê°€
            self.dataset.add_frame({
                "observation.image": img_tensor,
                "observation.image_secondary": img_secondary_tensor,
                "observation.state": self.latest_data["state"],
                "action": self.latest_data["action"],
                "task": "multi_cam_joint_task_v3"
            })
            self.frame_count += 1

    def _save_episode_internal(self):
        with self.lock:
            if self.frame_count == 0:
                self.status_msg = "âš ï¸ ë°ì´í„° ì—†ìŒ"
                self.is_saving = False
                return

            self.is_saving = True
            self.is_recording = False
            self.status_msg = "ğŸ’¾ ì €ì¥ ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”"

            try:
                self.dataset.save_episode()
                gr.Info(f"âœ… ì—í”¼ì†Œë“œ {self.dataset.num_episodes - 1} ì €ì¥ ì™„ë£Œ!")
                self.status_msg = "âœ… ì €ì¥ ì™„ë£Œ"
            except Exception as e:
                self.status_msg = "âŒ ì €ì¥ ì˜¤ë¥˜"
            finally:
                self.frame_count = 0
                self.elapsed_time = 0.0
                self.is_saving = False

    def start_rec(self):
        if self.dataset is None:
            self.status_msg = "âš ï¸ ë°ì´í„°ì…‹ ì´ˆê¸°í™”/ë¶ˆëŸ¬ì˜¤ê¸°ë¥¼ ë¨¼ì € í•´ì£¼ì„¸ìš”"
            return self.status_msg, 0, ""
        with self.lock:
            self._clear_buffer_internal()
            self.is_recording = True
            self.frame_count = 0
            self.start_time = time.time()
            self.elapsed_time = 0.0
            self.status_msg = "ğŸ”´ ë…¹í™” ì¤‘..."
        return self.status_msg, self.get_ep_count(), ""

    def retry_rec(self):
        if self.dataset is None: return self.status_msg, 0, ""
        with self.lock:
            self._clear_buffer_internal()
            self.is_recording = True
            self.frame_count = 0
            self.start_time = time.time()
            self.status_msg = "ğŸ”„ ì¬ì‹œë„ ì¤‘"
        return self.status_msg, self.get_ep_count(), ""

    def _clear_buffer_internal(self):
        if self.dataset is not None:
            if hasattr(self.dataset, 'clear_episode_buffer'):
                self.dataset.clear_episode_buffer()
            else:
                self.dataset._frames = []

    def next_episode(self):
        if self.dataset is None: return self.status_msg, 0, ""
        if self.is_recording:
            self.is_recording = False
            threading.Thread(target=self._save_episode_internal, daemon=True).start()
        return self.status_msg, self.get_ep_count(), ""

    def finalize_dataset(self):
        if self.dataset is None: return "âš ï¸ ë¯¸ì„¤ì •", 0, ""
        with self.lock:
            self.dataset.finalize()
            self.status_msg = "ğŸ ìˆ˜ì§‘ ì¢…ë£Œ"
            return self.status_msg, self.get_ep_count(), ""

    def update_ui_components(self):
        progress_val = 0
        bar_label = f"ì¤€ë¹„ ì™„ë£Œ: ìµœëŒ€ {self.max_time:.1f}s"
        if self.is_recording:
            progress_val = min(100, (self.elapsed_time / self.max_time) * 100)
            bar_label = f"âŒ› ë…¹í™” ì¤‘: {self.elapsed_time:.1f}s / {self.max_time:.1f}s"
        elif self.is_saving:
            progress_val, bar_label = 100, "ğŸ’¾ ì €ì¥ ì¤‘..."

        with self.lock:
            joints_deg = [np.rad2deg(val.item()) for val in self.latest_data["state"]]
            joint_str = (f"J1:{joints_deg[0]:>6.1f}Â° | J2:{joints_deg[1]:>6.1f}Â° | J3:{joints_deg[2]:>6.1f}Â°\n"
                         f"J4:{joints_deg[3]:>6.1f}Â° | J5:{joints_deg[4]:>6.1f}Â° | J6:{joints_deg[5]:>6.1f}Â°\n"
                         f"Gripper: {joints_deg[6]:.1f}Â°")

            # --- ë¼ë²¨ í…ìŠ¤íŠ¸ ìƒì„± ---
            main_label = f"Main (Kinect) | {self.res_main}"
            sub_label = f"Secondary Camera | {self.res_sub}"

        return (
            gr.update(value=self.current_frame_for_ui, label=main_label), # ë¼ë²¨ ì—…ë°ì´íŠ¸
            gr.update(value=self.current_frame_secondary_for_ui, label=sub_label), # ë¼ë²¨ ì—…ë°ì´íŠ¸
            gr.update(value=progress_val, label=bar_label),
            self.status_msg,
            self.get_ep_count(),
            joint_str
        )

# --- UI í•¨ìˆ˜ ---
def launch_ui(server_name:str, port:int, dt:float):
    if not rclpy.ok(): rclpy.init()
    recorder = GradioLeRobotVideoRecorder()
    threading.Thread(target=lambda: rclpy.spin(recorder), daemon=True).start()

    with gr.Blocks(title="LeRobot Collector v3.3") as demo:
        gr.Markdown("# ğŸ¤– LeRobot v3.3 ë©€í‹°ìº  ìˆ˜ì§‘ê¸° (Dynamic Label)")

        with gr.Accordion("âš™ï¸ ì„¤ì •", open=True):
            with gr.Row():
                repo_id_input = gr.Textbox(label="Repo ID", value="uon/multi-cam-joint-task")
                root_path_input = gr.Textbox(label="Root Path", value="outputs/dataset")
                max_time_input = gr.Number(label="ìµœëŒ€ ì‹œê°„(ì´ˆ)", value=10.0)
            init_btn = gr.Button("ğŸ”„ ë°ì´í„°ì…‹ ì´ˆê¸°í™”/ë¶ˆëŸ¬ì˜¤ê¸°")

        with gr.Row():
            with gr.Column(scale=2):
                with gr.Row():
                    # ì´ˆê¸° ë¼ë²¨ ì„¤ì •
                    image_output = gr.Image(label="Main Camera")
                    image_secondary_output = gr.Image(label="Secondary Camera")
                joint_info_display = gr.Textbox(label="í˜„ì¬ ë¡œë´‡ ì¡°ì¸íŠ¸ ê°ë„ (Degree)", lines=3, interactive=False)
                progress_bar = gr.Slider(label="ì¤€ë¹„ ì™„ë£Œ", minimum=0, maximum=100, value=0, interactive=False)

            with gr.Column(scale=1):
                ep_count_display = gr.Label(value="0", label="í˜„ì¬ ì—í”¼ì†Œë“œ ìˆ˜")
                status_text = gr.Label(value="ëŒ€ê¸° ì¤‘", label="í˜„ì¬ ìƒíƒœ")
                start_btn = gr.Button("ğŸ”´ ì‹œì‘", variant="primary")
                next_btn = gr.Button("ğŸ’¾ ì™„ë£Œ ë° ì €ì¥", variant="secondary")
                finish_btn = gr.Button("ğŸ ì „ì²´ í™•ì •", variant="stop")

        gr.Timer(dt).tick(
            recorder.update_ui_components,
            outputs=[image_output, image_secondary_output, progress_bar, status_text, ep_count_display, joint_info_display]
        )

        init_btn.click(recorder.init_dataset, inputs=[repo_id_input, root_path_input], outputs=[status_text, ep_count_display])
        start_btn.click(recorder.start_rec, outputs=[status_text, ep_count_display])
        next_btn.click(lambda: (recorder.next_episode()[0], recorder.get_ep_count()), outputs=[status_text, ep_count_display])
        finish_btn.click(recorder.finalize_dataset, outputs=[status_text, ep_count_display])

    demo.launch(server_name=server_name, server_port=port)
    rclpy.shutdown()

if __name__ == "__main__":
    launch_ui(
        server_name="127.0.0.1",
        port=7890,
        dt=1/60
    )