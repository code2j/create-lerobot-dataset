import gradio as gr
import torch
import numpy as np
from PIL import Image
from pathlib import Path
import shutil
import threading
import time
import os
from queue import Queue


import rclpy
from rclpy.node import Node
from sensor_msgs.msg import CompressedImage, JointState, Image as ROSImage
import cv2


try:
    from lerobot.datasets.lerobot_dataset import LeRobotDataset
except ImportError:
    import lerobot.datasets.lerobot_dataset as lr_ds
    LeRobotDataset = lr_ds.LeRobotDataset


class DatasetCollector(Node):
    def __init__(self):
        super().__init__('lerobot_data_collector')

        # --- ì´ˆê¸° ì„¤ì •ê°’ ---
        self.record_sec = 10
        self.wait_sec = 5
        self.repo_id = "uon"
        self.dataset_name = "triple-cam-dataset"
        self.root_path = "../outputs/dataset"  # ê¸°ë³¸ ë£¨íŠ¸ ê²½ë¡œ

        self.dataset = None
        self.is_recording = False
        self.is_waiting = False
        self.saved_episodes_count = 0
        self.fps = 30
        self.lock = threading.Lock()


        self.total_progress = 0
        self.status_msg = "ëŒ€ê¸° ì¤‘"

        # ë°ì´í„° ì €ì¥ ë³€ìˆ˜
        self.latest_image_top = None
        self.latest_image_wrist_right = None
        self.latest_image_wrist_left = None
        self.latest_joints_right = np.zeros(7, dtype=np.float32)
        self.latest_joints_left = np.zeros(7, dtype=np.float32)

        self.save_queue = Queue()
        self.is_saving_background = False

        # --- êµ¬ë…ì ì„¤ì • (ì¹´ë©”ë¼ 3ëŒ€ + ê´€ì ˆ 2ê°œ) ---
        self.sub_top = self.create_subscription(CompressedImage, '/right/camera/cam_top/color/image_rect_raw/compressed', self._top_image_callback, 10)
        self.sub_wrist_right = self.create_subscription(CompressedImage, '/right/camera/cam_wrist/color/image_rect_raw/compressed', self._wrist_right_image_callback, 10)
        self.sub_wrist_left = self.create_subscription(CompressedImage, '/left/camera/cam_wrist/color/image_rect_raw/compressed', self._wrist_left_image_callback, 10)
        self.sub_joints_right = self.create_subscription(JointState, '/joint_states', self._joint_right_callback, 10)
        self.sub_joints_left = self.create_subscription(JointState, '/left_robot/leader/joint_states', self._joint_left_callback, 10)


        # LeRobotì€ ì¼ë°˜ì ìœ¼ë¡œ (C, H, W) í˜•ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
        self.features_config = {
            "observation.state": (14,),
            "action": (14,),
            "observation.images.top": (3, 480, 640),
            "observation.images.wrist_right": (3, 480, 640),
            "observation.images.wrist_left": (3, 480, 640)
        }


        threading.Thread(target=lambda: rclpy.spin(self), daemon=True).start()
        threading.Thread(target=self._background_save_worker, daemon=True).start()


    # --- ì´ë¯¸ì§€ ë””ì½”ë”© ë° ì½œë°± ---
    def _decode_image(self, msg):
        try:
            np_arr = np.frombuffer(msg.data, np.uint8)
            cv_img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
            return Image.fromarray(cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB))
        except: return None


    def _top_image_callback(self, msg):
        img = self._decode_image(msg)
        if img:
            with self.lock: self.latest_image_top = img
    def _wrist_right_image_callback(self, msg):
        img = self._decode_image(msg)
        if img:
            with self.lock: self.latest_image_wrist_right = img
    def _wrist_left_image_callback(self, msg):
        img = self._decode_image(msg)
        if img:
            with self.lock: self.latest_image_wrist_left = img
    def _joint_right_callback(self, msg):
        with self.lock:
            if len(msg.position) >= 7: self.latest_joints_right = np.array(msg.position[:7], dtype=np.float32)
    def _joint_left_callback(self, msg):
        with self.lock:
            if len(msg.position) >= 7: self.latest_joints_left = np.array(msg.position[:7], dtype=np.float32)


    # --- ë°ì´í„°ì…‹ ì´ˆê¸°í™” ---
    def setup_dataset(self, root_path, repo_id, dataset_name, task_label, wait_sec, record_sec):
        self.root_path = root_path
        self.repo_id = repo_id
        self.dataset_name = dataset_name
        self.task_label = task_label
        self.wait_sec = wait_sec
        self.record_sec = record_sec


        # ê²½ë¡œ ìƒì„± ê·œì¹™: [ë£¨íŠ¸]/[Repo ID]/[ë°ì´í„°ì…‹ ì´ë¦„]
        full_save_dir = Path(self.root_path) / self.repo_id / self.dataset_name
        self.local_dir = full_save_dir.absolute()


        if self.local_dir.exists():
            shutil.rmtree(self.local_dir)

        # LeRobot ë°ì´í„°ì…‹ ìƒì„± ì‹œ repo_idëŠ” [ID]/[Name] í˜•ì‹ìœ¼ë¡œ ì „ë‹¬
        lerobot_repo_id = f"{self.repo_id}/{self.dataset_name}"

        # í•µì‹¬ ìˆ˜ì •: featuresì— "task"ë¥¼ ì¶”ê°€í•´ì•¼ add_frame ì‹œ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        # ë˜í•œ ì´ë¯¸ì§€ shapeë¥¼ (C, H, W) í˜•ì‹ìœ¼ë¡œ ë§ì¶”ëŠ” ê²ƒì´ ì•ˆì „í•©ë‹ˆë‹¤.
        features = {
            "observation.state": {"dtype": "float32", "shape": self.features_config["observation.state"]},
            "action": {"dtype": "float32", "shape": self.features_config["action"]},
            "observation.images.top": {"dtype": "video", "shape": self.features_config["observation.images.top"], "names": ["color"], "video_backend": "pyav"},
            "observation.images.wrist_right": {"dtype": "video", "shape": self.features_config["observation.images.wrist_right"], "names": ["color"], "video_backend": "pyav"},
            "observation.images.wrist_left": {"dtype": "video", "shape": self.features_config["observation.images.wrist_left"], "names": ["color"], "video_backend": "pyav"},
            "task": {"dtype": "string", "shape": (1,)},
        }

        self.dataset = LeRobotDataset.create(repo_id=lerobot_repo_id, root=self.local_dir, fps=self.fps, features=features, use_videos=True)
        return f"âœ… ì´ˆê¸°í™” ì„±ê³µ: {self.local_dir}"


    def start_workflow(self):
        if self.dataset is None: return "âŒ ì´ˆê¸°í™” ë¨¼ì € í•˜ì„¸ìš”."
        threading.Thread(target=self._workflow_loop, daemon=True).start()
        return "â³ ì¤€ë¹„ ì¤‘..."


    def _workflow_loop(self):
        total_time = self.wait_sec + self.record_sec
        self.is_waiting = True
        start_wait = time.time()
        while (time.time() - start_wait) < self.wait_sec:
            elapsed = time.time() - start_wait
            self.total_progress = (elapsed / total_time) * 100
            self.status_msg = f"â³ ëŒ€ê¸° ì¤‘... ({self.wait_sec - elapsed:.1f}s)"
            time.sleep(0.05)
        self.is_waiting = False


        self.is_recording = True
        frames_to_save = []
        start_rec = time.time()
        while self.is_recording:
            loop_start = time.time()
            elapsed_rec = loop_start - start_rec
            if elapsed_rec >= self.record_sec: break
            with self.lock:
                if all([self.latest_image_top, self.latest_image_wrist_right, self.latest_image_wrist_left]):
                    combined_state = np.concatenate([self.latest_joints_right, self.latest_joints_left])
                    frames_to_save.append({
                        "state": combined_state.copy(), "action": combined_state.copy(),
                        "img_top": self.latest_image_top.copy(), "img_wrist_r": self.latest_image_wrist_right.copy(), "img_wrist_l": self.latest_image_wrist_left.copy()
                    })
            self.total_progress = ((self.wait_sec + elapsed_rec) / total_time) * 100
            self.status_msg = f"ğŸ”´ ë…¹í™” ì¤‘... ({elapsed_rec:.1f}s)"
            time.sleep(max(0, (1.0 / self.fps) - (time.time() - loop_start)))


        self.is_recording = False
        if frames_to_save:
            self.save_queue.put(frames_to_save)
            self.status_msg = "âœ… ë…¹í™” ì™„ë£Œ! (ì €ì¥ ì¤‘)"
        self.total_progress = 0


    def _background_save_worker(self):
        while True:
            frames = self.save_queue.get()
            self.is_saving_background = True
            try:
                for f in frames:
                    # PIL Imageë¥¼ ê·¸ëŒ€ë¡œ ë„£ì–´ë„ LeRobotDatasetì´ ì²˜ë¦¬í•˜ì§€ë§Œ,
                    # featuresì— ì •ì˜ëœ shapeì™€ ì¼ì¹˜í•˜ëŠ”ì§€ ë‚´ë¶€ì ìœ¼ë¡œ ê²€ì¦í•©ë‹ˆë‹¤.
                    self.dataset.add_frame({
                        "observation.state": torch.from_numpy(f["state"]).float(),
                        "action": torch.from_numpy(f["action"]).float(),
                        "observation.images.top": f["img_top"],
                        "observation.images.wrist_right": f["img_wrist_r"],
                        "observation.images.wrist_left": f["img_wrist_l"],
                        "task": self.task_label,
                    })
                self.dataset.save_episode()
                self.saved_episodes_count += 1
                print(f"ì—í”¼ì†Œë“œ ì €ì¥ ì™„ë£Œ! í˜„ì¬ ì´: {self.saved_episodes_count}")
            except Exception as e:
                print(f"ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                import traceback
                traceback.print_exc() # ìƒì„¸ ì˜¤ë¥˜ ì¶œë ¥
            self.is_saving_background = False
            self.save_queue.task_done()


    def get_ui_data(self):
        display_status = self.status_msg
        if self.is_saving_background:
            display_status += f" ğŸ’¾ [ì €ì¥ ì¤‘... í:{self.save_queue.qsize()}]"

        total_time = self.wait_sec + self.record_sec
        marker_pos = (self.wait_sec / total_time) * 100
        bar_color = '#FFE0B2' if self.is_waiting else '#C8E6C9'

        html_bar = f"""
       <div style="width: 100%; background-color: #f5f5f5; border-radius: 6px; height: 35px; position: relative; overflow: hidden; border: 1px solid #ddd;">
           <div style="width: {self.total_progress}%; background-color: {bar_color}; height: 100%; transition: width 0.1s linear;"></div>
           <div style="position: absolute; left: {marker_pos}%; top: 0; width: 3px; height: 100%; background-color: #555; z-index: 10;"></div>
           <div style="position: absolute; width: 100%; text-align: center; top: 0; line-height: 35px; font-weight: bold; color: #444; pointer-events: none;">{display_status}</div>
       </div>
       """
        with self.lock:
            def fmt(joints, name):
                deg = [np.degrees(val) for val in joints]
                return f"[{name}] J1-6: {', '.join([f'{d:.1f}' for d in deg[:6]])} | G: {deg[6]:.1f}Â°"
            full_text = fmt(self.latest_joints_right, "Right") + "\n" + fmt(self.latest_joints_left, "Left")
            return html_bar, self.saved_episodes_count, self.latest_image_top, self.latest_image_wrist_right, self.latest_image_wrist_left, full_text


# --- ë©”ì¸ ì‹¤í–‰ ---
def main():
    rclpy.init()
    collector = DatasetCollector()

    with gr.Blocks() as demo:
        gr.Markdown("# ğŸ¤– Dual-Arm LeRobot Multi-Path Collector")

        with gr.Row():
            camera_top = gr.Image(label="Top Camera (Kinect)", streaming=True, interactive=False)
            camera_wrist_r = gr.Image(label="Right Wrist", streaming=True, interactive=False)
            camera_wrist_l = gr.Image(label="Left Wrist", streaming=True, interactive=False)

        joint_display = gr.Textbox(label="Robot Status (Degrees)", lines=2, interactive=False)

        with gr.Row():
            with gr.Column(scale=2):
                root_path = gr.Textbox(label="1. ë£¨íŠ¸ ì €ì¥ ê²½ë¡œ", value="outputs/dataset")
                repo_id = gr.Textbox(label="2. Repo ID (í´ë”ëª…)", value="uon")
                dataset_name = gr.Textbox(label="3. ë°ì´í„°ì…‹ ì´ë¦„", value="triple-cam-task")
            with gr.Column(scale=1):
                task_label = gr.Textbox(label="íƒœìŠ¤í¬ ë¼ë²¨", value="pick_up")
                wait_duration = gr.Number(label="ëŒ€ê¸° ì‹œê°„(ì´ˆ)", value=5)
                record_duration = gr.Number(label="ë…¹í™” ì‹œê°„(ì´ˆ)", value=10)
                ep_count_display = gr.Number(label="ì €ì¥ ì™„ë£Œ ì—í”¼ì†Œë“œ", value=0, interactive=False)
                init_btn = gr.Button("âš™ï¸ ê²½ë¡œ ì„¤ì • ë° ì´ˆê¸°í™”", variant="secondary")

        progress_html = gr.HTML()
        start_btn = gr.Button("ğŸ”´ ë…¹í™” ì‹œì‘", variant="primary")

        timer = gr.Timer(0.1)
        timer.tick(collector.get_ui_data, outputs=[progress_html, ep_count_display, camera_top, camera_wrist_r, camera_wrist_l, joint_display])

        init_btn.click(collector.setup_dataset,
                       [root_path, repo_id, dataset_name, task_label, wait_duration, record_duration],
                       ep_count_display)

        start_btn.click(collector.start_workflow)


    demo.launch(css=".gradio-container {max-width: 1400px !important}")
    rclpy.shutdown()


if __name__ == "__main__":
    main()
