import threading
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import CompressedImage
import cv2
import numpy as np
import torch
import gradio as gr
from pathlib import Path
from lerobot.datasets.lerobot_dataset import LeRobotDataset
import shutil
import time
import os

# í—ˆë¸Œ ì ‘ì† ì°¨ë‹¨ (ë¡œì»¬ ìš°ì„ )
os.environ["HF_HUB_OFFLINE"] = "1"

class GradioLeRobotVideoRecorder(Node):
    def __init__(self):
        super().__init__('gradio_lerobot_video_recorder')
        self.lock = threading.Lock()

        self.dataset = None
        self.repo_id = ""
        self.root_path = None

        self.is_recording = False
        self.is_saving = False
        self.frame_count = 0
        self.current_frame_for_ui = None
        self.current_frame_secondary_for_ui = None # ë‘ ë²ˆì§¸ UIìš© í”„ë ˆì„

        self.max_time = 10.0
        self.start_time = 0.0
        self.elapsed_time = 0.0
        self.status_msg = "ëŒ€ê¸° ì¤‘"

        self.latest_data = {
            "image": None,
            "image_secondary": None, # ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ ë²„í¼ ì¶”ê°€
            "state": torch.zeros(6),
            "action": torch.zeros(6)
        }

        # 1ë²ˆ ì¹´ë©”ë¼ (Kinect)
        self.subscription = self.create_subscription(
            CompressedImage, '/kinect/color/compressed', self._kinect_callback, 10)

        # 2ë²ˆ ì¹´ë©”ë¼ (í”Œë ˆì´ìŠ¤í™€ë” í† í”½)
        self.subscription_secondary = self.create_subscription(
            CompressedImage, '/right/camera/cam_wrist/color/image_rect_raw/compressed', self._secondary_callback, 10)

        self.create_timer(1.0 / 30.0, self._recording_loop)

    def get_ep_count(self):
        return self.dataset.num_episodes if self.dataset is not None else 0

    def init_dataset(self, repo_id, root_dir):
        with self.lock:
            try:
                self.repo_id = repo_id
                self.root_path = Path(root_dir).absolute()
                dataset_path = self.root_path / self.repo_id
                info_json = dataset_path / "meta" / "info.json"

                if info_json.exists():
                    self.dataset = LeRobotDataset(repo_id=self.repo_id, root=dataset_path)
                    print(f"\n[INFO] ê¸°ì¡´ ë°ì´í„°ì…‹ ë°œê²¬ ë° ë¡œë“œ ì™„ë£Œ")
                    gr.Info("ğŸ“‚ ê¸°ì¡´ ë°ì´í„°ì…‹ì„ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
                else:
                    self.dataset = LeRobotDataset.create(
                        repo_id=self.repo_id,
                        root=dataset_path,
                        fps=30,
                        features={
                            "observation.image": { # ë©”ì¸ ì¹´ë©”ë¼
                                "dtype": "video",
                                "shape": (3, 480, 640),
                                "names": ["channels", "height", "width"],
                                "info": {"fps": 30, "video_backend": "pyav"}
                            },
                            "observation.image_secondary": { # ë³´ì¡° ì¹´ë©”ë¼ ì¶”ê°€
                                "dtype": "video",
                                "shape": (3, 480, 640),
                                "names": ["channels", "height", "width"],
                                "info": {"fps": 30, "video_backend": "pyav"}
                            },
                            "observation.state": {"dtype": "float32", "shape": (6,)},
                            "action": {"dtype": "float32", "shape": (6,)},
                        },
                        use_videos=True,
                    )
                    print(f"\n[INFO] ìƒˆ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ (2-Cam ì„¤ì •)")
                    gr.Info("âœ¨ ìƒˆ ë°ì´í„°ì…‹(ë©€í‹°ìº )ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

                self.status_msg = "âœ… ì´ˆê¸°í™” ì™„ë£Œ"
                return self.status_msg, self.get_ep_count()
            except Exception as e:
                print(f"\n[ERROR] ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                gr.Error(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.status_msg = "âŒ ì´ˆê¸°í™” ì‹¤íŒ¨"
                return self.status_msg, 0

    def _kinect_callback(self, msg):
        np_arr = np.frombuffer(msg.data, np.uint8)
        img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
        if img is not None:
            img = cv2.resize(img, (640, 480))
            rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            with self.lock:
                self.latest_data["image"] = rgb_img
                self.current_frame_for_ui = rgb_img

    def _secondary_callback(self, msg):
        """ë‘ ë²ˆì§¸ ì¹´ë©”ë¼ ì½œë°± í•¨ìˆ˜"""
        np_arr = np.frombuffer(msg.data, np.uint8)
        img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
        if img is not None:
            img = cv2.resize(img, (640, 480))
            rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            with self.lock:
                self.latest_data["image_secondary"] = rgb_img
                self.current_frame_secondary_for_ui = rgb_img

    def _recording_loop(self):
        if not self.is_recording or self.dataset is None:
            return
        with self.lock:
            # ë‘ ì¹´ë©”ë¼ ë°ì´í„° ì¤‘ í•˜ë‚˜ë¼ë„ ì—†ìœ¼ë©´ ê¸°ë¡ ìŠ¤í‚µ (ë°ì´í„° ì •ë ¬ ìœ ì§€)
            if self.latest_data["image"] is None:
                return

            # ë³´ì¡° ì¹´ë©”ë¼ ë°ì´í„°ê°€ ì•„ì§ ì—†ë‹¤ë©´ ê²€ì€ìƒ‰ í™”ë©´ìœ¼ë¡œ ëŒ€ì²´ (ì—ëŸ¬ ë°©ì§€ìš©)
            if self.latest_data["image_secondary"] is None:
                img_secondary = np.zeros((480, 640, 3), dtype=np.uint8)
            else:
                img_secondary = self.latest_data["image_secondary"]

            self.elapsed_time = time.time() - self.start_time
            if self.elapsed_time >= self.max_time:
                self.is_recording = False
                threading.Thread(target=self._save_episode_internal, daemon=True).start()
                return

            img_tensor = torch.from_numpy(self.latest_data["image"]).permute(2, 0, 1)
            img_secondary_tensor = torch.from_numpy(img_secondary).permute(2, 0, 1)

            self.dataset.add_frame({
                "observation.image": img_tensor,
                "observation.image_secondary": img_secondary_tensor, # ì¶”ê°€ëœ í•„ë“œ ì €ì¥
                "observation.state": self.latest_data["state"],
                "action": self.latest_data["action"],
                "task": "multi_cam_task"
            })
            self.frame_count += 1

    def _save_episode_internal(self):
        with self.lock:
            if self.frame_count == 0:
                self.status_msg = "âš ï¸ ë°ì´í„° ì—†ìŒ"
                self.is_saving = False
                return

            self.is_saving = True
            self.is_recording = False
            self.status_msg = "ğŸ’¾ ì €ì¥ ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”"
            print(f"[SAVE] ë©€í‹°ìº  ë°ì´í„° ì¸ì½”ë”© ì¤‘... ({self.frame_count} í”„ë ˆì„)")

            try:
                self.dataset.save_episode()
                print(f"[SUCCESS] ì €ì¥ ì™„ë£Œ (ì´: {self.dataset.num_episodes})")
                gr.Info(f"âœ… ì—í”¼ì†Œë“œ {self.dataset.num_episodes - 1} ì €ì¥ ì™„ë£Œ!")
                self.status_msg = "âœ… ì €ì¥ ì™„ë£Œ"
            except Exception as e:
                print(f"[ERROR] ì €ì¥ ì˜¤ë¥˜: {e}")
                self.status_msg = "âŒ ì €ì¥ ì˜¤ë¥˜"
            finally:
                self.frame_count = 0
                self.elapsed_time = 0.0
                self.is_saving = False

    def start_rec(self):
        if self.dataset is None:
            gr.Warning("âš ï¸ ë¨¼ì € ë°ì´í„°ì…‹ ì´ˆê¸°í™”/ë¶ˆëŸ¬ì˜¤ê¸°ë¥¼ ì™„ë£Œí•´ ì£¼ì„¸ìš”!")
            return self.status_msg, 0
        if self.is_recording:
            gr.Info("ì´ë¯¸ ë…¹í™”ê°€ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.")
            return self.status_msg, self.get_ep_count()
        if self.is_saving:
            gr.Warning("â³ í˜„ì¬ ì €ì¥ ì‘ì—…ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.")
            return self.status_msg, self.get_ep_count()

        with self.lock:
            self._clear_buffer_internal()
            self.is_recording = True
            self.frame_count = 0
            self.start_time = time.time()
            self.elapsed_time = 0.0
            self.status_msg = "ğŸ”´ ë…¹í™” ì¤‘..."
            print(f"\n[REC] ë©€í‹°ìº  ë…¹í™” ì‹œì‘ (ìµœëŒ€ {self.max_time}ì´ˆ)")
        return self.status_msg, self.get_ep_count()

    def retry_rec(self):
        if self.dataset is None:
            gr.Warning("âš ï¸ ë¨¼ì € ë°ì´í„°ì…‹ ì´ˆê¸°í™”/ë¶ˆëŸ¬ì˜¤ê¸°ë¥¼ ì™„ë£Œí•´ ì£¼ì„¸ìš”!")
            return self.status_msg, 0
        with self.lock:
            self._clear_buffer_internal()
            self.is_recording = True
            self.frame_count = 0
            self.start_time = time.time()
            self.elapsed_time = 0.0
            self.status_msg = "ğŸ”„ ì¬ì‹œë„ ì¤‘"
            gr.Info("ğŸ”„ ì²˜ìŒë¶€í„° ë‹¤ì‹œ ë…¹í™”í•©ë‹ˆë‹¤.")
        return self.status_msg, self.get_ep_count()

    def _clear_buffer_internal(self):
        if self.dataset is not None:
            if hasattr(self.dataset, 'clear_episode_buffer'):
                self.dataset.clear_episode_buffer()
            else:
                self.dataset._frames = []

    def next_episode(self):
        if self.dataset is None:
            gr.Warning("âš ï¸ ë¨¼ì € ë°ì´í„°ì…‹ ì´ˆê¸°í™”/ë¶ˆëŸ¬ì˜¤ê¸°ë¥¼ ì™„ë£Œí•´ ì£¼ì„¸ìš”!")
            return self.status_msg, 0
        if self.is_recording:
            self.is_recording = False
            threading.Thread(target=self._save_episode_internal, daemon=True).start()
        return self.status_msg, self.get_ep_count()

    def finalize_dataset(self):
        if self.dataset is None:
            gr.Warning("âš ï¸ ë¨¼ì € ë°ì´í„°ì…‹ ì´ˆê¸°í™”/ë¶ˆëŸ¬ì˜¤ê¸°ë¥¼ ì™„ë£Œí•´ ì£¼ì„¸ìš”!")
            return "âš ï¸ ë¯¸ì„¤ì •", 0
        with self.lock:
            if self.is_recording or self.is_saving:
                gr.Warning("âš ï¸ ì‘ì—… ì¤‘ì—ëŠ” í™•ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return "âš ï¸ ì‘ì—… ì¤‘", self.get_ep_count()
            self.dataset.finalize()
            gr.Info("ğŸ ë°ì´í„°ì…‹ ìµœì¢… í™•ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            self.status_msg = "ğŸ ìˆ˜ì§‘ ì¢…ë£Œ"
            return self.status_msg, self.get_ep_count()

    def update_ui_components(self):
        progress_val = 0
        bar_label = f"ì¤€ë¹„ ì™„ë£Œ: ìµœëŒ€ {self.max_time:.1f}s"

        if self.is_recording:
            progress_val = min(100, (self.elapsed_time / self.max_time) * 100)
            bar_label = f"âŒ› ë…¹í™” ì¤‘: {self.elapsed_time:.1f}s / {self.max_time:.1f}s"
        elif self.is_saving:
            progress_val = 100
            bar_label = "ğŸ’¾ ì €ì¥ ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."

        return (
            self.current_frame_for_ui,
            self.current_frame_secondary_for_ui, # ë‘ ë²ˆì§¸ ì˜ìƒ UI ê°±ì‹ 
            gr.update(value=progress_val, label=bar_label),
            self.status_msg,
            self.get_ep_count()
        )

# --- UI í•¨ìˆ˜ ---
def launch_ui():
    global recorder
    if not rclpy.ok(): rclpy.init()
    recorder = GradioLeRobotVideoRecorder()

    ros_thread = threading.Thread(target=lambda: rclpy.spin(recorder), daemon=True)
    ros_thread.start()

    with gr.Blocks(title="LeRobot Collector") as demo:
        gr.Markdown("# ğŸ¤– LeRobot v3.0 ë©€í‹°ìº  ìˆ˜ì§‘ê¸°")

        with gr.Accordion("âš™ï¸ ì„¤ì •", open=True):
            with gr.Row():
                repo_id_input = gr.Textbox(label="Repo ID", value="uon/triple-cam-task-video")
                root_path_input = gr.Textbox(label="Root Path", value="outputs/dataset")
            max_time_input = gr.Number(label="ìµœëŒ€ ë…¹í™” ì‹œê°„ (ì´ˆ)", value=10.0, precision=1)
            init_btn = gr.Button("ğŸ”„ ë°ì´í„°ì…‹ ì´ˆê¸°í™”/ë¶ˆëŸ¬ì˜¤ê¸°")

        with gr.Row():
            with gr.Column(scale=2):
                with gr.Row(): # ì˜ìƒ í”¼ë“œ ë‘ ê°œ ë‚˜ë€íˆ ë°°ì¹˜
                    image_output = gr.Image(label="Main Camera (Kinect)")
                    image_secondary_output = gr.Image(label="Secondary Camera")

                progress_bar = gr.Slider(label="ì¤€ë¹„ ì™„ë£Œ", minimum=0, maximum=100, value=0, interactive=False)

            with gr.Column(scale=1):
                ep_count_display = gr.Label(value="0", label="í˜„ì¬ ì—í”¼ì†Œë“œ ìˆ˜")
                status_text = gr.Label(value="ëŒ€ê¸° ì¤‘", label="í˜„ì¬ ìƒíƒœ")

                with gr.Row():
                    start_btn = gr.Button("ğŸ”´ ì‹œì‘", variant="primary")
                    retry_btn = gr.Button("ğŸ”„ ë¦¬íŠ¸ë¼ì´", variant="secondary")

                next_btn = gr.Button("ğŸ’¾ ì™„ë£Œ ë° ì €ì¥", variant="secondary")
                finish_btn = gr.Button("ğŸ ì „ì²´ í™•ì •", variant="stop")

        gr.Timer(0.1).tick(
            recorder.update_ui_components,
            outputs=[image_output, image_secondary_output, progress_bar, status_text, ep_count_display]
        )

        init_btn.click(recorder.init_dataset, inputs=[repo_id_input, root_path_input], outputs=[status_text, ep_count_display])
        max_time_input.change(lambda v: setattr(recorder, 'max_time', float(v if v else 0)), inputs=max_time_input)
        start_btn.click(recorder.start_rec, outputs=[status_text, ep_count_display])
        retry_btn.click(recorder.retry_rec, outputs=[status_text, ep_count_display])
        next_btn.click(recorder.next_episode, outputs=[status_text, ep_count_display])
        finish_btn.click(recorder.finalize_dataset, outputs=[status_text, ep_count_display])

    demo.launch(server_name="0.0.0.0", server_port=7860)
    rclpy.shutdown()

if __name__ == "__main__":
    launch_ui()