import threading
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import CompressedImage
import cv2
import numpy as np
import torch
import gradio as gr
from pathlib import Path
from lerobot.datasets.lerobot_dataset import LeRobotDataset
import shutil
import time

class GradioLeRobotVideoRecorder(Node):
    def __init__(self):
        super().__init__('gradio_lerobot_video_recorder')
        self.lock = threading.Lock()

        # 1. ê²½ë¡œ ì„¤ì •
        self.repo_id = "uon/triple-cam-task-video"
        self.root_path = Path("../outputs")
        self.dataset_path = self.root_path / self.repo_id

        # 2. ë°ì´í„°ì…‹ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        if (self.dataset_path / "meta" / "info.json").exists():
            print(f"ğŸ“‚ [ê¸°ì¡´ ë°ì´í„°ì…‹ ë°œê²¬] ê²½ë¡œ: {self.dataset_path}")
            print("ğŸ”„ ê¸°ì¡´ ë°ì´í„°ì…‹ì— ì—í”¼ì†Œë“œë¥¼ ì´ì–´ì„œ ì €ì¥í•©ë‹ˆë‹¤.")

            self.dataset = LeRobotDataset(
                repo_id=self.repo_id,
                root=self.dataset_path
            )
        else:
            print(f"âœ¨ [ìƒˆ ë°ì´í„°ì…‹ ìƒì„±] ê²½ë¡œ: {self.dataset_path}")
            # ì´ ë‹¨ê³„ì—ì„œë§Œ .create()ê°€ í˜¸ì¶œë˜ì–´ í´ë”ë¥¼ ìƒˆë¡œ ë§Œë“­ë‹ˆë‹¤.
            self.dataset = LeRobotDataset.create(
                repo_id=self.repo_id,
                root=self.dataset_path,
                fps=30,
                features={
                    "observation.image": {
                        "dtype": "video",
                        "shape": (3, 480, 640),
                        "names": ["channels", "height", "width"],
                        "info": {"fps": 30, "video_backend": "pyav"}
                    },
                    "observation.state": {"dtype": "float32", "shape": (6,)},
                    "action": {"dtype": "float32", "shape": (6,)},
                },
                use_videos=True,
            )

        print(f"ğŸ“Š í˜„ì¬ ìˆ˜ì§‘ëœ ì´ ì—í”¼ì†Œë“œ: {self.dataset.num_episodes}")

        # 2. ìµœì‹  ë°ì´í„° ë²„í¼
        self.latest_data = {
            "image": None,
            "state": torch.zeros(6),
            "action": torch.zeros(6)
        }

        self.is_recording = False
        self.frame_count = 0
        self.current_frame_for_ui = None

        # 3. ROS2 êµ¬ë…
        self.subscription = self.create_subscription(
            CompressedImage, '/kinect/color/compressed', self._kinect_callback, 10)

        # 4. ê³ ì • ì£¼ê¸° íƒ€ì´ë¨¸ (30Hz)
        self.timer_period = 1.0 / 30.0
        self.record_timer = self.create_timer(self.timer_period, self._recording_loop)

    # ìˆ˜ì§‘í•˜ ë°ì´í„°ê°€ ì¶”ê°€ ë 
    def _kinect_callback(self, msg):
        np_arr = np.frombuffer(msg.data, np.uint8)
        img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
        if img is not None:
            img = cv2.resize(img, (640, 480))
            rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            with self.lock:
                self.latest_data["image"] = rgb_img
                self.current_frame_for_ui = rgb_img

    def _recording_loop(self):
        """ë°ì´í„° ì €ì¥ ë£¨í”„"""
        if not self.is_recording:
            return

        with self.lock:
            if self.latest_data["image"] is None:
                return

            img_tensor = torch.from_numpy(self.latest_data["image"]).permute(2, 0, 1)

            self.dataset.add_frame({
                "observation.image": img_tensor,
                "observation.state": self.latest_data["state"],
                "action": self.latest_data["action"],
                "task": "kinect_video_task"
            })
            self.frame_count += 1

    def start_rec(self):
        with self.lock:
            self.is_recording = True
            self.frame_count = 0
        return "ğŸ”´ ë…¹í™” ì‹œì‘ë¨..."

    def next_episode(self):
        with self.lock:
            if self.frame_count > 0:
                self.is_recording = False
                print(f"ğŸ¬ ì—í”¼ì†Œë“œ ì €ì¥ ì¤‘ ({self.frame_count} í”„ë ˆì„)...")
                self.dataset.save_episode()
                msg = f"âœ… ì—í”¼ì†Œë“œ ì €ì¥ ì™„ë£Œ! ({self.frame_count} í”„ë ˆì„)"
                self.frame_count = 0
                return msg
            return "âš ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

    def finalize_dataset(self):
        with self.lock:
            if self.is_recording: return "âš ï¸ ë…¹í™” ì¤‘ì—ëŠ” í™•ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            print("ğŸš€ ìµœì¢… ë°ì´í„°ì…‹ í™•ì • ì¤‘...")
            self.dataset.finalize()
            return "ğŸ ë°ì´í„°ì…‹ í™•ì • ì™„ë£Œ!"

# --- UI í•¨ìˆ˜ ---
def launch_ui():
    global recorder
    if not rclpy.ok(): rclpy.init()
    recorder = GradioLeRobotVideoRecorder()

    ros_thread = threading.Thread(target=lambda: rclpy.spin(recorder), daemon=True)
    ros_thread.start()

    with gr.Blocks(title="LeRobot Collector") as demo:
        gr.Markdown("# ğŸ¤– LeRobot í™•ì¥í˜• ìˆ˜ì§‘ê¸° (Fixed)")
        with gr.Row():
            with gr.Column(scale=2):
                image_output = gr.Image(label="Kinect Live Feed")
                # íƒ€ì´ë¨¸ë¥¼ í†µí•´ UI ì—…ë°ì´íŠ¸
                gr.Timer(0.1).tick(lambda: recorder.current_frame_for_ui, outputs=image_output)

            with gr.Column(scale=1):
                status_text = gr.Textbox(label="ìƒíƒœ", value="ëŒ€ê¸° ì¤‘")
                start_btn = gr.Button("ğŸ”´ ë…¹í™” ì‹œì‘", variant="primary")
                next_btn = gr.Button("ğŸ’¾ ì—í”¼ì†Œë“œ ì™„ë£Œ", variant="secondary")
                finish_btn = gr.Button("ğŸ ìµœì¢… í™•ì •", variant="stop")

        start_btn.click(recorder.start_rec, outputs=status_text)
        next_btn.click(recorder.next_episode, outputs=status_text)
        finish_btn.click(recorder.finalize_dataset, outputs=status_text)

    demo.launch(server_name="0.0.0.0", server_port=7860)
    rclpy.shutdown()

if __name__ == "__main__":
    launch_ui()