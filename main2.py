import gradio as gr
import cv2
import numpy as np
from pathlib import Path
import threading
import time
import queue
import os
import shutil

# NumPy 2.x í˜¸í™˜ì„± ê²½ê³  ë°©ì§€ë¥¼ ìœ„í•œ ì„¤ì •
os.environ["NUMPY_EXPERIMENTAL_ARRAY_FUNCTION"] = "0"

# ros2
from rclpy.node import Node
from sensor_msgs.msg import CompressedImage, JointState

# lerobot
from lerobot.datasets.lerobot_dataset import LeRobotDataset
from lerobot.datasets.utils import DEFAULT_FEATURES

from data_converter import decode_image
from subscriber_hub import SubscriberHub

class Dataset_manager:
    def __init__(self, subscriber_hub: SubscriberHub):
        self.subscriber_hub = subscriber_hub
        self.dataset = None
        self.is_recording = False
        self.running = True
        self.lock = threading.Lock()

        # ë¹„ë™ê¸° ì²˜ë¦¬ë¥¼ ìœ„í•œ í ì¶”ê°€
        self.data_queue = queue.Queue()

        self.max_record_time = 0
        self.start_time = 0
        self.fps = 30

        # 1. ìƒì‚°ì ì“°ë ˆë“œ: ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ íì— ë„£ìŒ
        self.record_thread = threading.Thread(target=self._recording_loop, daemon=True)
        self.record_thread.start()

        # 2. ì†Œë¹„ì ì“°ë ˆë“œ: íì—ì„œ ë°ì´í„°ë¥¼ êº¼ë‚´ ë””ì½”ë”© ë° ì €ì¥
        self.consumer_thread = threading.Thread(target=self._consumer_loop, daemon=True)
        self.consumer_thread.start()

        print("[Info ] ë…¹í™” ë° ì†Œë¹„ì ì“°ë ˆë“œê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def init_dataset(self, repo_id, root_dir, task_name, fps) -> str:
        """ë°ì´í„°ì…‹ ì´ˆê¸°í™” ë° ìƒì„±"""
        with self.lock:
            self.repo_id = repo_id
            self.root_path = Path(root_dir).absolute()
            self.task_name = task_name
            self.fps = fps

            dataset_path = self.root_path / self.repo_id

            joint_names = [
                'right_joint1', 'right_joint2', 'right_joint3',
                'right_joint4', 'right_joint5', 'right_joint6',
                'right_rh_r1_joint'
            ]

            features = DEFAULT_FEATURES.copy()
            features[f'observation.images.cam_top'] = {
                'dtype': 'video',
                'names': ['height', 'width', 'channels'],
                'shape': (720, 1280, 3)
            }
            features[f'observation.images.cam_wrist'] = {
                'dtype': 'video',
                'names': ['height', 'width', 'channels'],
                'shape': (480, 848, 3)
            }
            features[f'observation.state'] = {
                'dtype': 'float32',
                'names': joint_names,
                'shape': (7,)
            }
            features[f'action'] = {
                'dtype': 'float32',
                'names': joint_names,
                'shape': (7,)
            }

            self.dataset = LeRobotDataset.create(
                repo_id=self.repo_id,
                root=dataset_path,
                features=features,
                use_videos=True,
                fps=fps,
                robot_type="omy_f3m",
                image_writer_processes=2,
                image_writer_threads=4,
            )

            print(f"[Info ] ë°ì´í„°ì…‹ì´ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return "ë°ì´í„°ì…‹ ì´ˆê¸°í™” ì„±ê³µ"

    def _recording_loop(self):
        """ìƒì‚°ì: ì •ë°€í•œ íƒ€ì´ë°ì— ë§ì¶° ë°ì´í„°ë§Œ ìˆ˜ì§‘í•˜ì—¬ íì— ì‚½ì…"""
        next_time = time.time()

        while self.running:
            if self.is_recording and self.dataset is not None:
                frame_interval = 1.0 / self.fps

                if self.max_record_time > 0:
                    if time.time() - self.start_time >= self.max_record_time:
                        self.stop_recording()
                        continue

                # 1. ë°ì´í„° ìˆ˜ì§‘
                raw_data = self.subscriber_hub.get_latest_data()

                # 2. íì— ì‚½ì… (ì—í”¼ì†Œë“œ êµ¬ë¶„ì„ ìœ„í•´ í˜„ì¬ ì—í”¼ì†Œë“œ ì¸ë±ìŠ¤ í¬í•¨ ê°€ëŠ¥)
                self.data_queue.put(raw_data)

                # 3. ì •ë°€ íƒ€ì´ë° ì œì–´
                next_time += frame_interval
                sleep_time = next_time - time.time()
                if sleep_time > 0:
                    time.sleep(sleep_time)
                else:
                    next_time = time.time()
            else:
                time.sleep(0.1)
                next_time = time.time()

    def _consumer_loop(self):
        """ì†Œë¹„ì: íì—ì„œ ë°ì´í„°ë¥¼ êº¼ë‚´ ë¬´ê±°ìš´ ì‘ì—… ìˆ˜í–‰"""
        while self.running:
            try:
                raw_data = self.data_queue.get(timeout=0.1)

                if self.dataset is not None:
                    kinect_msg, wrist_msg, follow_msg, leader_msg = raw_data
                    kinect_img = decode_image(kinect_msg)
                    wrist_img = decode_image(wrist_msg)
                    follower_joint_data = np.array(follow_msg.position, dtype=np.float32)
                    leader_joint_data = np.array(leader_msg.position, dtype=np.float32)

                    if kinect_img is not None and wrist_img is not None:
                        with self.lock:
                            if self.dataset is not None:
                                self.dataset.add_frame({
                                    f'observation.images.cam_top': kinect_img,
                                    f'observation.images.cam_wrist': wrist_img,
                                    f'observation.state': follower_joint_data,
                                    f'action': leader_joint_data,
                                    f'task': self.task_name
                                })

                self.data_queue.task_done()
            except queue.Empty:
                continue
            except Exception as e:
                print(f"[Error] ì†Œë¹„ì ë£¨í”„ ì˜¤ë¥˜: {e}")

    def start_recording(self, max_time=0):
        if self.dataset is None:
            return "ì˜¤ë¥˜: ë°ì´í„°ì…‹ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

        # ì¦‰ì‹œ ë‹¤ìŒ ë…¹í™”ê°€ ê°€ëŠ¥í•˜ë„ë¡ íë¥¼ ë¹„ìš°ì§€ ì•Šê³  ìƒíƒœë§Œ ë³€ê²½
        # (ì´ì „ ë…¹í™” ë°ì´í„°ëŠ” ì†Œë¹„ì ì“°ë ˆë“œê°€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ê³„ì† ì²˜ë¦¬ ì¤‘)
        self.max_record_time = max_time
        self.start_time = time.time()
        self.is_recording = True

        msg = "ì‹œìŠ¤í…œ: ë…¹í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤."
        print(msg)
        return msg

    def stop_recording(self):
        if not self.is_recording:
            return "ì‹œìŠ¤í…œ: í˜„ì¬ ë…¹í™” ì¤‘ì´ ì•„ë‹™ë‹ˆë‹¤."

        self.is_recording = False

        # ì¦‰ì‹œ ì €ì¥ì„ í˜¸ì¶œí•˜ëŠ” ëŒ€ì‹ , ë³„ë„ ì“°ë ˆë“œì—ì„œ íê°€ ë¹„ì›Œì§€ë©´ ì €ì¥í•˜ë„ë¡ í•¨
        threading.Thread(target=self._wait_and_save, daemon=True).start()

        print("ì‹œìŠ¤í…œ: ë…¹í™”ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì €ì¥ì„ ì§„í–‰í•©ë‹ˆë‹¤.")
        return "ì‹œìŠ¤í…œ: ë…¹í™” ì¤‘ë‹¨ (ë°±ê·¸ë¼ìš´ë“œ ì €ì¥ ì¤‘)"

    def _wait_and_save(self):
        """ë°±ê·¸ë¼ìš´ë“œì—ì„œ íê°€ ë¹„ì›Œì§ˆ ë•Œê¹Œì§€ ê¸°ë‹¤ë¦° í›„ ì €ì¥"""
        # í˜„ì¬ ì‹œì ì˜ í ì‘ì—…ì´ ëë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
        self.data_queue.join()

        with self.lock:
            if self.dataset is not None:
                self.dataset.save_episode()
                self.dataset.finalize()
                print("ì‹œìŠ¤í…œ: ì—í”¼ì†Œë“œ ì €ì¥ ì™„ë£Œ")

    def close(self):
        self.running = False
        self.record_thread.join()
        self.consumer_thread.join()
        print("ì‹œìŠ¤í…œ: ëª¨ë“  ì“°ë ˆë“œê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

class GradioVisualizer:
    def __init__(self, subscriber_hub: SubscriberHub):
        self.subscriber_hub = subscriber_hub
        self.update_interval = 1/30
        self.dataset_manager = Dataset_manager(self.subscriber_hub)

    def ui_timer_callback(self):
        (k_msg, w_msg, f_joint, l_joint) = self.subscriber_hub.get_latest_data()
        k_img = decode_image(k_msg)
        w_img = decode_image(w_msg)

        desired_names = ['right_joint1', 'right_joint2', 'right_joint3', 'right_joint4', 'right_joint5', 'right_joint6', 'right_rh_r1_joint']

        follower_text = "N/A"
        if f_joint is not None:
            f_vals = [np.rad2deg(f_joint.position[f_joint.name.index(n)]) if n in f_joint.name else np.nan for n in desired_names]
            follower_text = f"J1: {f_vals[0]:.1f} J2: {f_vals[1]:.1f} J3: {f_vals[2]:.1f} J4: {f_vals[3]:.1f} J5: {f_vals[4]:.1f} J6: {f_vals[5]:.1f} G: {f_vals[6]:.1f}"

        leader_text = "N/A"
        if l_joint is not None:
            l_vals = [np.rad2deg(l_joint.position[l_joint.name.index(n)]) if n in l_joint.name else np.nan for n in desired_names]
            leader_text = f"J1: {l_vals[0]:.1f} J2: {l_vals[1]:.1f} J3: {l_vals[2]:.1f} J4: {l_vals[3]:.1f} J5: {l_vals[4]:.1f} J6: {l_vals[5]:.1f} G: {l_vals[6]:.1f}"

        # ìƒíƒœ ë° í”„ë¡œì„¸ìŠ¤ í‘œì‹œ
        q_size = self.dataset_manager.data_queue.qsize()
        if self.dataset_manager.is_recording:
            elapsed = time.time() - self.dataset_manager.start_time
            status = f"ğŸ”´ ë…¹í™” ì¤‘... {elapsed:.1f}s | ëŒ€ê¸° í: {q_size}"
        else:
            if q_size > 0:
                status = f"â³ ë°±ê·¸ë¼ìš´ë“œ ì €ì¥ ì¤‘... (ë‚¨ì€ ì‘ì—…: {q_size})"
            else:
                status = "âœ… ëŒ€ê¸° ì¤‘ (ëª¨ë“  ì‘ì—… ì™„ë£Œ)"

        return k_img, w_img, follower_text, leader_text, status

    def create_interface(self):
        default_root_dir = os.path.join(os.getcwd(), "dataset")
        with gr.Blocks(title="Robot Data Collector") as demo:
            with gr.Row():
                kinect_image = gr.Image(label="Kinect", type="numpy")
                wrist_image = gr.Image(label="Wrist", type="numpy")

            with gr.Row():
                follower_joint_output = gr.Textbox(label="Follower Arm Joints")
                leader_joint_output = gr.Textbox(label="Leader Arm Joints")

            with gr.Row():
                repo_id_input = gr.Textbox(label="Repo ID", value="test_dataset")
                root_dir_input = gr.Textbox(label="Root Path", value=default_root_dir)
                task_name_input = gr.Textbox(label="Task", value="test_task")
                fps_input = gr.Number(label="FPS", value=30)
                max_time_input = gr.Number(label="Max Time", value=0)

            init_btn = gr.Button("Initialize")
            status_output = gr.Textbox(label="Status")

            with gr.Row():
                record_btn = gr.Button("Record", variant="primary")
                stop_btn = gr.Button("Stop", variant="stop")

            init_btn.click(self.dataset_manager.init_dataset, [repo_id_input, root_dir_input, task_name_input, fps_input], status_output)
            record_btn.click(self.dataset_manager.start_recording, [max_time_input], status_output)
            stop_btn.click(self.dataset_manager.stop_recording, outputs=status_output)

            timer = gr.Timer(value=self.update_interval)
            timer.tick(self.ui_timer_callback, outputs=[kinect_image, wrist_image, follower_joint_output, leader_joint_output, status_output])
        return demo

    def launch(self):
        self.create_interface().launch(server_name="0.0.0.0", server_port=7860)

if __name__ == "__main__":
    import rclpy
    rclpy.init()
    hub = SubscriberHub()
    threading.Thread(target=lambda: rclpy.spin(hub), daemon=True).start()
    GradioVisualizer(hub).launch()
