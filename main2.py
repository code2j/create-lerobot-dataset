import gradio as gr
import cv2
import numpy as np
from pathlib import Path
import threading
import time
import queue
import os
import shutil
import subprocess
import signal

# NumPy 2.x í˜¸í™˜ì„± ê²½ê³  ë°©ì§€ë¥¼ ìœ„í•œ ì„¤ì •
os.environ["NUMPY_EXPERIMENTAL_ARRAY_FUNCTION"] = "0"

# ros2
from rclpy.node import Node
from sensor_msgs.msg import CompressedImage, JointState

# lerobot
from lerobot.datasets.lerobot_dataset import LeRobotDataset
from lerobot.datasets.utils import DEFAULT_FEATURES

from data_converter import decode_image
from subscriber_hub import SubscriberHub

class Dataset_manager:
    def __init__(self, subscriber_hub: SubscriberHub):
        self.subscriber_hub = subscriber_hub
        self.dataset = None
        self.is_recording = False
        self.running = True
        self.lock = threading.Lock()

        # ë¹„ë™ê¸° ì²˜ë¦¬ë¥¼ ìœ„í•œ í ì¶”ê°€
        self.data_queue = queue.Queue()

        self.max_record_time = 0
        self.start_time = 0
        self.fps = 30

        self.joint_names = [
            'right_joint1', 'right_joint2', 'right_joint3',
            'right_joint4', 'right_joint5', 'right_joint6',
            'right_rh_r1_joint'
        ]

        # 1. ìƒì‚°ì ì“°ë ˆë“œ: ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ íì— ë„£ìŒ
        self.record_thread = threading.Thread(target=self._recording_loop, daemon=True)
        self.record_thread.start()

        # 2. ì†Œë¹„ì ì“°ë ˆë“œ: íì—ì„œ ë°ì´í„°ë¥¼ êº¼ë‚´ ë””ì½”ë”© ë° ì €ì¥
        self.consumer_thread = threading.Thread(target=self._consumer_loop, daemon=True)
        self.consumer_thread.start()

        print("[Info ] ë…¹í™” ë° ì†Œë¹„ì ì“°ë ˆë“œê°€ ì‹œì‘")

    def init_dataset(self, repo_id, root_dir, task_name, fps) -> str:
        """ë°ì´í„°ì…‹ ì´ˆê¸°í™” ë° ìƒì„±"""
        with self.lock:
            self.repo_id = repo_id
            self.root_path = Path(root_dir).absolute()
            self.task_name = task_name
            self.fps = fps

            dataset_path = self.root_path / self.repo_id

            features = DEFAULT_FEATURES.copy()
            features[f'observation.images.cam_top'] = {
                'dtype': 'video',
                'names': ['height', 'width', 'channels'],
                'shape': (720, 1280, 3)
            }
            features[f'observation.images.cam_wrist'] = {
                'dtype': 'video',
                'names': ['height', 'width', 'channels'],
                'shape': (480, 848, 3)
            }
            features[f'observation.state'] = {
                'dtype': 'float32',
                'names': self.joint_names,
                'shape': (7,)
            }
            features[f'action'] = {
                'dtype': 'float32',
                'names': self.joint_names,
                'shape': (7,)
            }

            self.dataset = LeRobotDataset.create(
                repo_id=self.repo_id,
                root=dataset_path,
                features=features,
                use_videos=True,
                fps=fps,
                robot_type="omy_f3m",
            )

            print(f"[Info ] ë°ì´í„°ì…‹ì´ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return "ë°ì´í„°ì…‹ ì´ˆê¸°í™” ì„±ê³µ"

    def _recording_loop(self):
        """ìƒì‚°ì: ì •ë°€í•œ íƒ€ì´ë°ì— ë§ì¶° ë°ì´í„°ë§Œ ìˆ˜ì§‘í•˜ì—¬ íì— ì‚½ì…"""
        next_time = time.time()

        while self.running:
            if self.is_recording and self.dataset is not None:
                frame_interval = 1.0 / self.fps

                if self.max_record_time > 0:
                    if time.time() - self.start_time >= self.max_record_time:
                        self.stop_recording()
                        continue

                # 1. ë°ì´í„° ìˆ˜ì§‘
                raw_data = self.subscriber_hub.get_latest_msg()

                # 2. íì— ì‚½ì…
                self.data_queue.put(raw_data)

                # 3. ì •ë°€ íƒ€ì´ë° ì œì–´
                next_time += frame_interval
                sleep_time = next_time - time.time()
                if sleep_time > 0:
                    time.sleep(sleep_time)
                else:
                    next_time = time.time()
            else:
                time.sleep(0.1)
                next_time = time.time()

    def _consumer_loop(self):
        """íì—ì„œ ë°ì´í„°ë¥¼ êº¼ë‚´ ì‘ì—… ìˆ˜í–‰(ë””ì½”ë”© ë° ë³€í™˜)"""
        while self.running:
            try:
                raw_data = self.data_queue.get(timeout=0.1)

                if self.dataset is not None:
                    kinect_msg, wrist_msg, follow_msg, leader_msg = raw_data

                    # 1. ì´ë¯¸ì§€ ì²˜ë¦¬ (ë””ì½”ë”©)
                    kinect_img = decode_image(kinect_msg)
                    wrist_img = decode_image(wrist_msg)

                    # 2. íŒ”ë¡œì›Œ(State) ë°ì´í„° ì •ë ¬
                    follow_map = dict(zip(follow_msg.name, follow_msg.position))
                    follower_joint_data = np.array([follow_map[name] for name in self.joint_names], dtype=np.float32)

                    # 3. ë¦¬ë”(Action) ë°ì´í„° ì •ë ¬
                    leader_map = dict(zip(leader_msg.name, leader_msg.position))
                    leader_joint_data = np.array([leader_map[name] for name in self.joint_names], dtype=np.float32)

                    # 4. ë°ì´í„°ì…‹ ì¶”ê°€
                    if kinect_img is not None and wrist_img is not None:
                        with self.lock:
                            self.dataset.add_frame({
                                'observation.images.cam_top': kinect_img,
                                'observation.images.cam_wrist': wrist_img,
                                'observation.state': follower_joint_data,
                                'action': leader_joint_data,
                                'task': self.task_name
                            })

                self.data_queue.task_done()
            except queue.Empty:
                continue
            except Exception as e:
                print(f"[Error] ì†Œë¹„ì ë£¨í”„ ì˜¤ë¥˜: {e}")


    def toggle_recording(self, max_time=0):
        """ìŠ¤í˜ì´ìŠ¤ë°” ë‹¨ì¶•í‚¤ë¥¼ ìœ„í•œ í† ê¸€ ê¸°ëŠ¥: ìƒíƒœì— ë”°ë¼ ë¶„ê¸°"""
        if self.is_recording:
            return self.stop_recording()
        else:
            return self.start_recording(max_time)

    def start_recording(self, max_time=0):
        if self.dataset is None:
            return "ì˜¤ë¥˜: ë°ì´í„°ì…‹ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

        if self.is_recording:
            return "ì‹œìŠ¤í…œ: ì´ë¯¸ ë…¹í™” ì¤‘ì…ë‹ˆë‹¤."

        self.max_record_time = max_time
        self.start_time = time.time()
        self.is_recording = True

        msg = "ì‹œìŠ¤í…œ: ë…¹í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. (Space í‚¤ë¡œ ì¤‘ë‹¨ ê°€ëŠ¥)"
        print(msg)
        return msg

    def stop_recording(self):
        if not self.is_recording:
            return "ì‹œìŠ¤í…œ: í˜„ì¬ ë…¹í™” ì¤‘ì´ ì•„ë‹™ë‹ˆë‹¤."

        self.is_recording = False

        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ íê°€ ë¹„ì›Œì§€ë©´ ì €ì¥í•˜ë„ë¡ í•¨
        threading.Thread(target=self._wait_and_save, daemon=True).start()

        msg = "ì‹œìŠ¤í…œ: ë…¹í™” ì¤‘ë‹¨ (ë°±ê·¸ë¼ìš´ë“œ ì €ì¥ ì¤‘)"
        print(msg)
        return msg

    def _wait_and_save(self):
        """ë°±ê·¸ë¼ìš´ë“œì—ì„œ íê°€ ë¹„ì›Œì§ˆ ë•Œê¹Œì§€ ê¸°ë‹¤ë¦° í›„ ì €ì¥"""
        print("ì‹œìŠ¤í…œ: ë‚¨ì€ ë°ì´í„°ë¥¼ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤...")
        self.data_queue.join()

        with self.lock:
            if self.dataset is not None:
                try:
                    self.dataset.save_episode()
                    print("ì‹œìŠ¤í…œ: ì—í”¼ì†Œë“œ ì €ì¥ ì™„ë£Œ")
                except Exception as e:
                    print(f"ì‹œìŠ¤í…œ: ì—í”¼ì†Œë“œ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")

    def finalize_dataset(self):
        """ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ ë° ë°ì´í„°ì…‹ ìµœì¢…í™”"""
        if self.dataset is None:
            return "ì˜¤ë¥˜: ë°ì´í„°ì…‹ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

        if self.is_recording:
            return "ì˜¤ë¥˜: ë…¹í™” ì¤‘ì—ëŠ” ë°ì´í„°ì…‹ì„ ì™„ë£Œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        if not self.data_queue.empty():
            return "ì‹œìŠ¤í…œ: ì•„ì§ ì²˜ë¦¬ ì¤‘ì¸ ë°ì´í„°ê°€ ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

        with self.lock:
            try:
                self.dataset.finalize()
                msg = "ì‹œìŠ¤í…œ: ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ ë° ë°ì´í„°ì…‹ ìµœì¢…í™” ì„±ê³µ"
                print(msg)
                return msg
            except Exception as e:
                msg = f"ì‹œìŠ¤í…œ: ë°ì´í„°ì…‹ ìµœì¢…í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
                print(msg)
                return msg

    def close(self):
        self.running = False
        self.record_thread.join()
        self.consumer_thread.join()
        print("ì‹œìŠ¤í…œ: ëª¨ë“  ì“°ë ˆë“œê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

class GradioVisualizer:
    def __init__(self, subscriber_hub: SubscriberHub):
        self.subscriber_hub = subscriber_hub
        self.update_interval = 1/30
        self.dataset_manager = Dataset_manager(self.subscriber_hub)

    def ui_timer_callback(self):
        (k_msg, w_msg, f_joint, l_joint) = self.subscriber_hub.get_latest_msg()
        k_img = decode_image(k_msg)
        w_img = decode_image(w_msg)

        desired_names = ['right_joint1', 'right_joint2', 'right_joint3', 'right_joint4', 'right_joint5', 'right_joint6', 'right_rh_r1_joint']

        follower_text = "N/A"
        if f_joint is not None:
            f_vals = [np.rad2deg(f_joint.position[f_joint.name.index(n)]) if n in f_joint.name else np.nan for n in desired_names]
            follower_text = f"J1: {f_vals[0]:.1f} J2: {f_vals[1]:.1f} J3: {f_vals[2]:.1f} J4: {f_vals[3]:.1f} J5: {f_vals[4]:.1f} J6: {f_vals[5]:.1f} G: {f_vals[6]:.1f}"

        leader_text = "N/A"
        if l_joint is not None:
            l_vals = [np.rad2deg(l_joint.position[l_joint.name.index(n)]) if n in l_joint.name else np.nan for n in desired_names]
            leader_text = f"J1: {l_vals[0]:.1f} J2: {l_vals[1]:.1f} J3: {l_vals[2]:.1f} J4: {l_vals[3]:.1f} J5: {l_vals[4]:.1f} J6: {l_vals[5]:.1f} G: {l_vals[6]:.1f}"

        # ìƒíƒœ ë° í”„ë¡œì„¸ìŠ¤ í‘œì‹œ
        q_size = self.dataset_manager.data_queue.qsize()
        if self.dataset_manager.is_recording:
            elapsed = time.time() - self.dataset_manager.start_time
            status = f"ğŸ”´ ë…¹í™” ì¤‘... {elapsed:.1f}s | ëŒ€ê¸° í: {q_size}"
        else:
            if q_size > 0:
                status = f"â³ ë°±ê·¸ë¼ìš´ë“œ ì €ì¥ ì¤‘... (ë‚¨ì€ ì‘ì—…: {q_size})"
            else:
                status = "âœ… ëŒ€ê¸° ì¤‘ (ëª¨ë“  ì‘ì—… ì™„ë£Œ)"

        return k_img, w_img, follower_text, leader_text, status

    def create_interface(self):
        default_root_dir = os.path.join(os.getcwd(), "dataset")

        # ìŠ¤í˜ì´ìŠ¤ë°” ê°ì§€ë¥¼ ìœ„í•œ JavaScript
        js_code = """
        function() {
            document.addEventListener('keydown', function(e) {
                if (e.code === 'Space') {
                    const active = document.activeElement;
                    if (active.tagName === 'INPUT' || active.tagName === 'TEXTAREA' || active.isContentEditable) {
                        return;
                    }
                    e.preventDefault();
                    // ìˆ¨ê²¨ì§„ í† ê¸€ ë²„íŠ¼ì„ í´ë¦­í•˜ê²Œ í•¨
                    const btn = document.getElementById('toggle_btn');
                    if (btn) btn.click();
                }
            });
        }
        """

        with gr.Blocks(title="Robot Data Collector") as demo:
            gr.Markdown("# ğŸ¤– Robot Data Collector")

            with gr.Row():
                kinect_image = gr.Image(label="Kinect", type="numpy")
                wrist_image = gr.Image(label="Wrist", type="numpy")

            with gr.Row():
                follower_joint_output = gr.Textbox(label="Follower Arm Joints")
                leader_joint_output = gr.Textbox(label="Leader Arm Joints")

            with gr.Row():
                repo_id_input = gr.Textbox(label="Repo ID", value="test_dataset")
                root_dir_input = gr.Textbox(label="Root Path", value=default_root_dir)
                task_name_input = gr.Textbox(label="Task", value="test_task")
                fps_input = gr.Number(label="FPS", value=30)
                max_time_input = gr.Number(label="Max Time", value=0)

            init_btn = gr.Button("Initialize")
            status_output = gr.Textbox(label="Status")

            with gr.Row():
                # ë²„íŠ¼ ì´ë¦„ì„ ëª…í™•í•˜ê²Œ ìˆ˜ì •
                record_btn = gr.Button("Record", variant="primary")
                stop_btn = gr.Button("Stop", variant="stop")
                finalize_btn = gr.Button("ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ (Finalize)", variant="secondary")

            # ìŠ¤í˜ì´ìŠ¤ë°” ì „ìš© ìˆ¨ê²¨ì§„ ë²„íŠ¼ (UIì—ëŠ” ë³´ì´ì§€ ì•ŠìŒ)
            toggle_btn = gr.Button("Toggle Recording", visible=False, elem_id="toggle_btn")

            init_btn.click(self.dataset_manager.init_dataset, [repo_id_input, root_dir_input, task_name_input, fps_input], status_output)

            # ëª…ì‹œì  ë²„íŠ¼ ì´ë²¤íŠ¸
            record_btn.click(self.dataset_manager.start_recording, [max_time_input], status_output)
            stop_btn.click(self.dataset_manager.stop_recording, outputs=status_output)
            finalize_btn.click(self.dataset_manager.finalize_dataset, outputs=status_output)

            # ìŠ¤í˜ì´ìŠ¤ë°” í† ê¸€ ì´ë²¤íŠ¸ (ìƒíƒœì— ë”°ë¼ ìë™ ë¶„ê¸°)
            toggle_btn.click(self.dataset_manager.toggle_recording, [max_time_input], status_output)

            timer = gr.Timer(value=self.update_interval)
            timer.tick(
                self.ui_timer_callback,
                outputs=[
                    kinect_image, wrist_image, follower_joint_output, leader_joint_output,
                    status_output
                ]
            )

            self.js_code = js_code

        return demo

    def launch(self):
        demo = self.create_interface()
        demo.launch(server_name="0.0.0.0", server_port=7860, js=self.js_code)

if __name__ == "__main__":
    import rclpy
    rclpy.init()
    hub = SubscriberHub()
    # ROS2 Spinì„ ë³„ë„ ì“°ë ˆë“œì—ì„œ ì‹¤í–‰
    threading.Thread(target=lambda: rclpy.spin(hub), daemon=True).start()

    visualizer = GradioVisualizer(hub)
    try:
        visualizer.launch()
    except KeyboardInterrupt:
        visualizer.dataset_manager.close()
        rclpy.shutdown()